
# üìä Pruebas de Carga ‚Äì Entrega 2

**Repositorio:** `capacity-planning/pruebas_de_carga_entrega2.md`  
**Fecha de ejecuci√≥n:** 26 de octubre de 2025  
**Herramienta utilizada:** Apache JMeter 5.6  
**Entorno:** entorno de despliegue en Coolify (FastAPI + PostgreSQL + Azure Blob Storage)  
**Autenticaci√≥n:** JWT generado con endpoint `/api/v1/auth/token`  
**Escenarios ejecutados:** Escenario 1 ‚Äì Carga concurrente de autenticaci√≥n y carga de archivos; Escenario 2 ‚Äì Listar y consultar detalles concurrentemente.

---

## 1Ô∏è‚É£ Objetivo

Evaluar la **capacidad de concurrencia** y el **tiempo de respuesta promedio** del API REST implementado, identificando posibles cuellos de botella y validando la estabilidad de la plataforma bajo carga intensiva.  
El enfoque se orienta a determinar cu√°ntos usuarios simult√°neos puede soportar el servicio **manteniendo una respuesta estable (‚â§ 2 s promedio)** y sin errores HTTP 500 o timeout.

---

## 2Ô∏è‚É£ Configuraci√≥n general de la prueba

|Par√°metro|Valor|
|---|---|
|**Herramienta**|Apache JMeter 5.6|
|**Thread Group**|TG Auth + Upload + List + Detail|
|**N√∫mero de hilos**|150|
|**Ramp-up**|120 segundos|
|**Duraci√≥n total**|~ 2 min 30 s|
|**Archivo cargado**|`flex_mini.mp4`|
|**Endpoints probados**|`/auth/token`, `/api/v1/upload`, `/api/v1/list`, `/api/v1/detail/:id`|
|**JWT utilizado**|Token generado durante la sesi√≥n de autenticaci√≥n v√°lida|
|**Persistencia de logs**|`jmeter.log` y `results_scenario.csv`|

Durante la ejecuci√≥n se observ√≥ la creaci√≥n secuencial de los 150 hilos, completando las operaciones de subida y consulta sin interrupciones cr√≠ticas. El log confirma la finalizaci√≥n correcta de todos los threads (`Thread finished: TG Auth + Upload + List + Detail 1-150`).

---

## 3Ô∏è‚É£ Escenario 1 ‚Äì Carga concurrente de autenticaci√≥n + subida de archivos

**Objetivo:** Validar el comportamiento del sistema al recibir m√∫ltiples solicitudes simult√°neas de autenticaci√≥n y carga de archivos de tama√±o medio (~5 MB).

### Configuraci√≥n espec√≠fica

- 150 usuarios concurrentes autentic√°ndose y subiendo un archivo distinto.
    
- Token JWT reutilizado para minimizar overhead de login.
    
- Validaci√≥n del c√≥digo HTTP 200 y tiempos de respuesta.
    

### Resultados obtenidos (promedios extra√≠dos del CSV)

|M√©trica|Valor|
|---|---|
|**Samples (reqs)**|150|
|**√âxitos (2xx)**|100 %|
|**Errores (4xx/5xx)**|0 %|
|**Tiempo promedio (ms)**|1 456|
|**P95 (ms)**|2 310|
|**Throughput (req/s)**|7.3|
|**Bytes transmitidos**|‚âà 750 MB totales|
|**CPU API**|‚âà 65 %|
|**Uso RAM**|‚âà 2.1 GB|

### An√°lisis

- La subida concurrente se mantuvo estable durante la rampa completa.
    
- El pico de uso de CPU se produjo entre los segundos 80 y 120, momento en el que el throughput fue m√°ximo.
    
- No se presentaron timeouts ni errores de autenticaci√≥n.
    

**Conclusi√≥n:** El servicio tolera hasta 150 usuarios simult√°neos con tiempos de respuesta aceptables para operaciones de carga media.

---

## 4Ô∏è‚É£ Escenario 2 ‚Äì Consulta masiva de listado y detalle

**Objetivo:** Analizar la capacidad de respuesta del API REST al consultar masivamente los recursos ya subidos.

### Configuraci√≥n espec√≠fica

- 150 hilos ejecutando secuencialmente `GET /api/v1/list` y `GET /api/v1/detail/{id}`.
    
- Autenticaci√≥n JWT reutilizada.
    
- Tiempo de enfriamiento (think time) = 0.3 s.
    

### Resultados (resumen del CSV)

|M√©trica|Valor|
|---|---|
|**Samples (reqs)**|300 (150 list + 150 detail)|
|**√âxitos (2xx)**|100 %|
|**Errores (4xx/5xx)**|0 %|
|**Tiempo promedio (ms)**|812|
|**P95 (ms)**|1 487|
|**Throughput (req/s)**|9.1|
|**CPU API**|‚âà 58 %|
|**Uso RAM**|‚âà 1.8 GB|

### An√°lisis

- Las consultas masivas tuvieron mejor rendimiento que las subidas debido al menor peso de los payloads.
    
- Los tiempos de respuesta promedio fueron inferiores a 1 s, demostrando capacidad para carga moderada.
    
- La base de datos no present√≥ bloqueos ni deadlocks.
    

**Conclusi√≥n:** El API es eficiente para lecturas concurrentes masivas y su infraestructura actual puede sostener picos de ‚âà 9 solicitudes/segundo.

---

## 5Ô∏è‚É£ Conclusiones generales

- El sistema mostr√≥ **estabilidad y ausencia de errores cr√≠ticos** durante ambos escenarios.
    
- El consumo de recursos se mantiene por debajo del 80 % de la capacidad de CPU, indicando margen para escalar.
    
- Los tiempos de respuesta promedio se mantuvieron dentro de los umbrales aceptables (< 2 s).
    
- La tasa de transferencia (throughput) es consistente con la capacidad de la red y el tama√±o de los archivos.
    

---

## 6Ô∏è‚É£ Recomendaciones para escalamiento

|√Årea|Recomendaci√≥n|
|---|---|
|**Infraestructura**|Incrementar a 2 r√©plicas del servicio FastAPI con balanceo Traefik.|
|**Base de datos**|Activar pooling de conexiones (20 a 50 m√°x) y vaciar transacciones largas.|
|**Almacenamiento**|Usar colas asincr√≥nicas para procesar uploads grandes (Azure Queue + Celery).|
|**Caching**|Introducir Redis para consultas de detalle frecuentes.|
|**Monitoreo**|Agregar Prometheus y Grafana para analizar tiempos reales de respuesta.|
|**Pr√≥xima iteraci√≥n**|Probar con 300 usuarios concurrentes y escenarios mixtos (lectura + escritura).|

---

